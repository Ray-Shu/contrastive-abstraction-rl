{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "import platform\n",
    "use_mac_workaround = platform.system() == \"Darwin\"  # True on macOS\n",
    "\n",
    "if use_mac_workaround:\n",
    "    os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "    os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "    torch.set_num_threads(1)\n",
    "    faiss.omp_set_num_threads(1)\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\")) \n",
    "if project_root not in sys.path: \n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import torch \n",
    "import faiss \n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import psutil\n",
    "\n",
    "from models.cl_model import mlpCL \n",
    "import minari \n",
    "from utils.sampling_states import sample_states\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at /Users/ray/Documents/Research Assistancy UofA 2025/Reproduce Paper/contrastive-abstraction-RL/saved_models/best_model_laplace_15.ckpt, loading...\n"
     ]
    }
   ],
   "source": [
    "MINARI_DATASET = minari.load_dataset(\"D4RL/pointmaze/large-v2\")\n",
    "DEVICE = \"cpu\"\n",
    "PROJECT_ROOT = project_root\n",
    "TOTAL_STATES = 1_000_000\n",
    "\n",
    "# Load trained CL model \n",
    "model_name = \"best_model_laplace_15.ckpt\"\n",
    "pretrained_model_file = os.path.join(project_root+ \"/saved_models\", model_name) \n",
    "\n",
    "if os.path.isfile(pretrained_model_file): \n",
    "    print(f\"Found pretrained model at {pretrained_model_file}, loading...\") \n",
    "    cl_model = mlpCL.load_from_checkpoint(pretrained_model_file, map_location=torch.device(DEVICE))\n",
    "else:\n",
    "    print(\"Did not find a model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cmhn(): \n",
    "    def __init__(self, update_steps = 1, topk = 256, use_gpu = False, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Continuous Modern Hopfield Network \n",
    "\n",
    "        Args: \n",
    "            update_steps: The number of iterations the cmhn will do. (Usually just one).\n",
    "            topk: Using faiss, only the top k most similar patterns will be used. (more efficient in batch-wise updates) \n",
    "            use_gpu: Tells faiss if we use faiss-cpu or faiss-gpu for behind the scenes calculations. \n",
    "            device: The device that torch will use. \n",
    "        \"\"\"\n",
    "        self.update_steps = update_steps \n",
    "        self.topk = topk\n",
    "        self.use_gpu = use_gpu\n",
    "        self.device = torch.device(device)\n",
    "        self.index = None \n",
    "\n",
    "    def __build_index(self, X, d): \n",
    "        \"\"\"\n",
    "        Builds a faiss index (an object) for efficient searching of top-k patterns from X. \n",
    "        \"\"\"\n",
    "        X_np = X.detach().cpu().numpy().astype(\"float32\") # convert X from tensor to numpy \n",
    "\n",
    "        if self.use_gpu: \n",
    "            flat_index = faiss.IndexFlatL2(d) \n",
    "            self.index = faiss.index_cpu_to_all_gpus(flat_index)\n",
    "        else: \n",
    "            self.index = faiss.IndexFlatL2(d)\n",
    "        \n",
    "        self.index.add(X_np)\n",
    "    \n",
    "    def __update(self, X, xi, beta): \n",
    "        \"\"\"\n",
    "        The update rule for a continuous modern hopfield network. \n",
    "\n",
    "        Args: \n",
    "            X: The stored patterns. X is of size [N, d], where N is the number of patterns, and d the size of the patterns. \n",
    "            xi: The state pattern (ie. the current pattern being updated). xi is of size [d, 1]. \n",
    "            beta: The scalar inverse-temperature hyperparamater. Controls the number of metastable states that occur in the energy landscape. \n",
    "                - High beta corresponds to low temp, more separation between patterns.  \n",
    "                - Low beta corresponds to high temp, less separation (more metastable states). \n",
    "        \"\"\"\n",
    "        X_norm = F.normalize(X, p=2, dim=1)\n",
    "        xi_norm = F.normalize(xi, p=2, dim=0)\n",
    "        sims = X_norm @ xi_norm  # simularity between stored patterns and current pattern \n",
    "        p = F.softmax(beta * sims, dim=0, dtype=torch.float32)  # softmax dist along patterns (higher probability => more likely to be that stored pattern)\n",
    "        # p of size [N, 1] \n",
    "\n",
    "        X_T = X_norm.transpose(0, 1) \n",
    "        xi_new = X_T @ p  # xi_new, the updated state pattern; size [d, 1]\n",
    "        return xi_new\n",
    "\n",
    "    def __run_batch(self, X, queries, beta=None): \n",
    "        \"\"\"\n",
    "        Runs the mhn batch-wise for efficient computation. \n",
    "\n",
    "        Args: \n",
    "            X: Stored patterns, size [N, d].\n",
    "            queries: Input queries, size [N, d].\n",
    "            beta: The beta value per sample, size [N].\n",
    "        \"\"\"        \n",
    "        \n",
    "        assert beta != None, \"Must have a value for beta.\" \n",
    "        assert X.shape == queries.shape, \"X and queries must be the same shape! (N, d).\"\n",
    "        N, d = X.shape \n",
    "        self.__build_index(X, d) \n",
    "\n",
    "        queries_np = queries.detach().cpu().numpy().astype(\"float32\")\n",
    "        distances, indices = self.index.search(queries_np, self.topk)\n",
    "        \n",
    "        queries = torch.from_numpy(queries_np).to(X.device)\n",
    "        indices = torch.from_numpy(indices).to(X.device) # indices of shape [N, topk]\n",
    "\n",
    "        topk_X = X[indices] # size [N, topk, d] \n",
    "        topk_q = queries.unsqueeze(1) # change queries from [N, d] to [N, 1, d] for broadcasting\n",
    "        \n",
    "        # dot product of x_ij * q_i along \"d dim\" to obtain tensor of [N, topk]\n",
    "        # q_i represents the i'th query\n",
    "        # x_ij represents the corresponding i'th query and j'th pattern, where j is among the topk \n",
    "        # then sum over d to obtain the similarity between row i and col j. \n",
    "        sims = torch.sum(topk_X * topk_q, dim=-1) \n",
    "\n",
    "        beta = beta.view(-1, 1)  # beta: [N, 1], broadcasting beta. \n",
    "        sims = beta * sims       # sims * beta: [N, topk]\n",
    "        probs = F.softmax(sims, dim=-1) # calculate probs along patterns (NOT queries) ie. along topk --> [N, topk]\n",
    "        \n",
    "        # weighted sum over topk_X: x_ij * probs_i\n",
    "        xi_new = torch.sum(probs.unsqueeze(-1) * topk_X, dim=1) \n",
    "\n",
    "        return xi_new\n",
    "\n",
    "    def run(self, X, xi, beta=None, run_as_batch=False): \n",
    "        \"\"\"\n",
    "        Runs the network. \n",
    "\n",
    "        Args: \n",
    "            X: The stored patterns. X is of size [N, d], where B is the batches, N is the number of patterns, and d the size of the patterns. \n",
    "            xi: The state pattern (ie. the current pattern being updated). xi is of size [d, 1]. xi can also be a batch of queries [N, d].\n",
    "            beta: The scalar inverse-temperature hyperparamater. Controls the number of metastable states that occur in the energy landscape. \n",
    "                - High beta corresponds to low temp, more separation between patterns.  \n",
    "                - Low beta corresponds to high temp, less separation (more metastable states). \n",
    "        \"\"\"\n",
    "        assert beta != None, \"Must have a value for beta.\"\n",
    "\n",
    "        #if not isinstance(beta, torch.Tensor):\n",
    "        #   beta = torch.as_tensor(beta, dtype=torch.float32)\n",
    "\n",
    "        X = X.to(self.device)\n",
    "        xi = xi.to(self.device)\n",
    "        beta = beta.to(self.device)\n",
    "\n",
    "        if run_as_batch: \n",
    "            if xi.dim() == 1: \n",
    "                raise ValueError(\"Query shape should be [N, d] when updating as a batch.\")\n",
    "            \n",
    "            for _ in range(self.update_steps): \n",
    "                xi = self.__run_batch(X, xi, beta)\n",
    "            return xi\n",
    "        \n",
    "        else:\n",
    "            # if xi is of size [d], then change to [d, 1] \n",
    "            if xi.dim() == 1: \n",
    "                xi = xi.unsqueeze(1) #[d, 1]\n",
    "            elif xi.dim() == 2 and xi.size(1) != 1: \n",
    "                raise ValueError(\"Query shape should be [d] or [d, 1].\") \n",
    "\n",
    "            for _ in range(self.update_steps): \n",
    "                xi = self.__update(X, xi, beta)\n",
    "            return xi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = sample_states(MINARI_DATASET, TOTAL_STATES,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = d[\"states\"]\n",
    "\n",
    "# Subsample from the states array so there isn't so much clutter on visualization\n",
    "#idx = np.random.choice(np.arange(TOTAL_STATES), size=100_000, replace=False)\n",
    "#new_states = states[idx] \n",
    "\n",
    "subsampled_states = []\n",
    "idx = np.random.choice(np.arange(TOTAL_STATES), size=50_000, replace=False)\n",
    "subsampled_states = states[idx]  # [N, 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 4)\n",
      "torch.Size([50000, 32])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad(): \n",
    "    z = cl_model(torch.as_tensor(subsampled_states, dtype=torch.float32))\n",
    "\n",
    "# z of size [N, 32]\n",
    "\n",
    "print(subsampled_states.shape)\n",
    "print(z.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "chn = cmhn(update_steps=1, topk=256, use_gpu = False, device = DEVICE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage: 1460.96128 MB\n"
     ]
    }
   ],
   "source": [
    "beta = torch.as_tensor(35.0, dtype=torch.float32)\n",
    "print(f\"Memory usage: {psutil.Process(os.getpid()).memory_info().rss / 1e6} MB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.autograd.set_detect_anomaly(True): \n",
    "    U = chn.run(z, z, beta, run_as_batch=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50000, 32])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_dupes(x, k=1000, threshold=0.99): \n",
    "    x = x / np.linalg.norm(x, axis=1, keepdims=True)  # l2 normalize for cosine sim \n",
    "\n",
    "    index = faiss.IndexFlatIP(x.shape[1])\n",
    "    index.add(x)\n",
    "\n",
    "    D, I = index.search(x, k+1)\n",
    "\n",
    "    N = x.shape[0]\n",
    "    mask = np.ones(N, dtype=bool)\n",
    "    visited = np.zeros(N, dtype=bool)\n",
    "\n",
    "    # Finds the most similar vectors and masks them out.\n",
    "    for i in range(N):\n",
    "        if visited[i]:\n",
    "            continue\n",
    "        neighbors = I[i, 1:]  # skip self-match\n",
    "        similarities = D[i, 1:]\n",
    "        for j, sim in zip(neighbors, similarities):\n",
    "            if sim > threshold:\n",
    "                mask[j] = False\n",
    "                visited[j] = True\n",
    "\n",
    "    return x[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/89/s23t762151989wcy_1bx9vqc0000gn/T/ipykernel_33792/3619683181.py:2: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  x = x / np.linalg.norm(x, axis=1, keepdims=True)  # l2 normalize for cosine sim\n"
     ]
    }
   ],
   "source": [
    "u = remove_dupes(U, k = 5000, threshold= 0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([183, 32])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -0.1593,   1.8885,   3.8210,   0.2488,   3.0884,   2.6527,  -0.8658,\n",
      "          -4.8314,  -0.4564,  -0.2040,  -4.2156,  -7.8757,  -4.5268,   3.5428,\n",
      "           1.6113,  -4.3523,   8.5002,  -6.9940,   5.2944,  -3.7729,   1.7530,\n",
      "          -2.0040,  -5.4662,   1.4627,   2.1636,  -2.8145,  -3.0785,   1.1415,\n",
      "          -4.8897, -11.8525,  -4.7602,   3.5978],\n",
      "        [ -9.0760,   6.4994,  -7.3232,   1.5715,  -7.5245,  -4.3644,  -7.8839,\n",
      "          -4.1005,   2.9459,   6.0185,  -3.5223,   3.5647,   6.4049,   3.3934,\n",
      "           3.1928,  -3.8362,  -1.5759,   4.1450,   6.3996,   6.7548,   1.0043,\n",
      "           2.1827,  -0.5473,  -3.9415,   4.2520,  -4.2653,   2.8234,  -1.9857,\n",
      "           0.9425,   0.3422,   1.6241,   4.9217],\n",
      "        [ -4.6427,  -3.3330,  -4.9547,  -5.9786,   0.0777,  -7.2652,   1.2147,\n",
      "          -1.9109,  -0.5800,  -6.1060,  -0.4300,  -2.4197,  -0.9425,  -5.5252,\n",
      "          -2.6725,  -1.9154,  -2.1081,   2.5641,  -7.0463,  -1.1112, -11.1808,\n",
      "          -2.0582,   3.9627,   5.8540,   8.8195,   0.9126,   1.2695,   4.9150,\n",
      "          -6.3510,  -0.2297,   3.1034,  -3.8600]])\n"
     ]
    }
   ],
   "source": [
    "print(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CL_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
