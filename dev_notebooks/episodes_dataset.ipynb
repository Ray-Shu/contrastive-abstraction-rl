{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys \n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\")) \n",
    "if project_root not in sys.path: \n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utils.tensor_utils import split_data\n",
    "from models.cl_model import mlpCL\n",
    "\n",
    "import minari\n",
    "import torch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EpisodesDataset(torch.utils.data.Dataset): \n",
    "    def __init__(self, cl_model = None, minari_dataset = \"D4RL/pointmaze/large-v2\", n_episodes=1, episodeData=None):\n",
    "        \"\"\"\n",
    "        Dataset to store the z-representation of the states of their corresponding episodes. \n",
    "\n",
    "        Args: \n",
    "            cl_model: A pretrained contrastive learning model to encode states to z-representations. \n",
    "            minari_dataset: The type of minari dataset to use.\n",
    "            n_episodes: The number of episodes to sample. \n",
    "            episodeData: If you want to import the episodeData from minari into this dataset. \n",
    "\n",
    "        \"\"\"\n",
    "        assert cl_model != None, \"Must input a contrastive learning model to obtain z-representations!\"\n",
    "\n",
    "        self.cl_model = cl_model \n",
    "\n",
    "        if episodeData: \n",
    "            self.episodeData = episodeData\n",
    "        else: \n",
    "            self.minari_dataset = minari.load_dataset(minari_dataset)\n",
    "            self.episodeData = self.minari_dataset.sample_episodes(n_episodes=n_episodes) # list of episodes [ep1, ep2, ep3, ...]\n",
    "\n",
    "        # precompute all z representations and store them \n",
    "        self.z_data = [] \n",
    "        with torch.no_grad(): \n",
    "            for ep in self.episodeData: \n",
    "                x = torch.as_tensor(ep.observations[\"observation\"], dtype=torch.float32)\n",
    "                z = cl_model(x)\n",
    "                self.z_data.append(z) \n",
    "\n",
    "    def __len__(self): \n",
    "        \"\"\"\n",
    "        Returns the number of episodes in the dataset. \n",
    "        \"\"\"\n",
    "        return len(self.z_data)\n",
    "\n",
    "    def __getitem__(self, idx): \n",
    "        \"\"\"\n",
    "        Returns the z-representation specified by \"idx\". \n",
    "        This sample is the list of states in the form of a tensor. \n",
    "        \"\"\"\n",
    "        return self.z_data[idx]\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at /Users/ray/Documents/Research Assistancy UofA 2025/Reproduce Paper/contrastive-abstraction-RL/saved_models/best_model.ckpt, loading...\n"
     ]
    }
   ],
   "source": [
    "# Load trained CL model \n",
    "model_name = \"best_model.ckpt\"\n",
    "pretrained_model_file = os.path.join(project_root+ \"/saved_models\", model_name) \n",
    "\n",
    "if os.path.isfile(pretrained_model_file): \n",
    "    print(f\"Found pretrained model at {pretrained_model_file}, loading...\") \n",
    "    cl_model = mlpCL.load_from_checkpoint(pretrained_model_file, map_location=torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cl_model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([633, 32])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minari_dataset = minari.load_dataset(\"D4RL/pointmaze/large-v2\")\n",
    "episodeData = minari_dataset.sample_episodes(3360)\n",
    "\n",
    "train, val = split_data(episodeData, 0.7)\n",
    "\n",
    "train_ds = EpisodesDataset(cl_model=cl_model, episodeData=train)\n",
    "val_ds = EpisodesDataset(cl_model=cl_model, episodeData=val)\n",
    "\n",
    "train_ds[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  4.4051,  -0.3216,   2.7463,  ...,  -6.9307,   2.3275,  14.7764],\n",
       "        [  5.4566,  -1.6109,   2.5574,  ...,  -6.3021,   2.4560,  14.9638],\n",
       "        [  5.2345,  -2.7181,   1.7200,  ...,  -6.5735,   2.8840,  14.8254],\n",
       "        ...,\n",
       "        [ 12.8086, -27.9627, -23.3460,  ...,  24.1302, -11.9508,  10.4717],\n",
       "        [ 13.1106, -28.3226, -23.2933,  ...,  23.9085, -12.0890,   9.9810],\n",
       "        [ 13.6523, -28.4744, -22.7852,  ...,  23.9270, -12.5379,   9.2509]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CL_RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
